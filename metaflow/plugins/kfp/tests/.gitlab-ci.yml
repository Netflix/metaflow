include:
  - project: 'analytics/artificial-intelligence/ai-platform/aip-infrastructure/ci-templates/ci-cd-template'
    ref: &include_ref 'v2'
    file: 'environments/devex.yml'
  - project: 'analytics/artificial-intelligence/ai-platform/aip-infrastructure/ci-templates/ci-cd-template'
    ref: *include_ref
    file: '/blocks/python.yml'

variables:
  PY_LIBRARY_NAME: "zillow-metaflow"
  MAJOR_VERSION: "1"
  MINOR_VERSION: "0"
  METAFLOW_VERSION_PATH: "setup.py"
  IMAGE_REPOSITORY_TAG_PATH: 'image_tag_file.txt'
  # Run on the Internal cluster only on commit.
  # We run the tests via the integration test framework for Non-Prod/Prod.
  DEPLOY_INTERNAL: "true"
  DEPLOY_NONPROD: "false"
  DEPLOY_PROD: "false"

stages:
  - build
  - test

.path_to_host_file_directory: # obtains the path to file on the host machine, which is needed to mount a Docker on Docker
  script: &path-to-host-file-directory
  - export CONTAINER_ID=$(docker ps -q -f "label=com.gitlab.gitlab-runner.job.id=$CI_JOB_ID" -f "label=com.gitlab.gitlab-runner.type=build")
  - export MOUNT_NAME=$(docker inspect $CONTAINER_ID -f "{{ range .Mounts }}{{ if eq .Destination \"/builds\" }}{{ .Source }}{{end}}{{end}}")
  - export SHARED_PATH=$MOUNT_NAME/$CI_PROJECT_PATH

.version: &version |
  # Extract the open source Metaflow version as the basis for our forked library version.
  METAFLOW_VERSION=$(cat $METAFLOW_VERSION_PATH | sed -nr "s/^version = ['\"]([^'\"]*)['\"]$/\1/p")

  if [ "${CI_COMMIT_BRANCH}" = "${CI_DEFAULT_BRANCH}" ]; then
    PY_LIBRARY_VERSION="${MAJOR_VERSION}.${MINOR_VERSION}.${CI_PIPELINE_IID}.${METAFLOW_VERSION}"
  else
    PY_LIBRARY_VERSION="0.0.${CI_PIPELINE_IID}.${METAFLOW_VERSION}"
  fi
  IMAGE_TAG="${PY_LIBRARY_VERSION}"

.test:
  extends: .generate_kubeconfig
  stage: test
  variables:
    GIT_STRATEGY: none
    PIPELINE_VERSION: "1.0"
  script:
    - *path-to-host-file-directory  
    - export BUILT_IMAGE_FULL_PATH=$( cat ${IMAGE_REPOSITORY_TAG_PATH} )
    - cp -r /root/.kube .
    - docker run
        --rm
        -v ${SHARED_PATH}/.kube:/home/zservice/.kube
        -v ${SHARED_PATH}/public:/home/zservice/public  
        -e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID 
        -e AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY 
        -e AWS_SESSION_TOKEN=$AWS_SESSION_TOKEN 
        -e AWS_DEFAULT_REGION=$AWS_DEFAULT_REGION 
        -e KFP_RUN_URL_PREFIX=$KFP_RUN_URL_PREFIX 
        -e KFP_SDK_NAMESPACE=$KFP_SDK_NAMESPACE 
        -e USER=$GITLAB_USER_EMAIL
        ${BUILT_IMAGE_FULL_PATH}
        bash -c "
          cd /home/zservice/metaflow/metaflow/plugins/kfp/tests &&
          python -m pytest -s -n 3 run_integration_tests.py --image ${BUILT_IMAGE_FULL_PATH} --opsgenie-api-token ${OPSGENIE_API_TOKEN} --cov-config=setup.cfg
        "
  artifacts:
    when: always
    paths:
      - public
  

build:docker:
  stage: build
  script:
    - *version
    - export IMAGE_REPOSITORY_TAG=${DOCKER_REPO_URL}/${CI_PROJECT_NAMESPACE}/${PY_LIBRARY_NAME}:${IMAGE_TAG}
    - 'docker build --no-cache -f metaflow/plugins/kfp/tests/Dockerfile -t ${IMAGE_REPOSITORY_TAG} .'
    - 'echo ${DOCKER_API_KEY} | docker login -u ${DOCKER_USERNAME} --password-stdin ${DOCKER_REPO_URL}'
    - STDERR=$(docker push ${IMAGE_REPOSITORY_TAG} 2>&1 >/dev/null) || true
    - echo $STDERR
    - |
      if [ -z "$STDERR" ] || [[ $STDERR == *"manifest invalid"* ]]; then
        echo "Successful!"
      else
        echo "Error in pushing image to Artifactory." >&2
        exit 1
      fi
    - echo ${IMAGE_REPOSITORY_TAG} > ${IMAGE_REPOSITORY_TAG_PATH}
  artifacts:
    paths:
      - ${IMAGE_REPOSITORY_TAG_PATH}

build:publish:
  extends: .aip_python_debian_image
  stage: build
  script:
  - *version
  # Now write back the zillow-kfp version back to the original location we found the original so
  # python package managers can reference it as they need the version stored internally.
  - sed -i "s/\(version = ['\"]\)[^'\"]*\(['\"]\)/\1${PY_LIBRARY_VERSION}\2/" $METAFLOW_VERSION_PATH
  - python setup.py sdist
  # Set up the configuration for Artifactory to publish the python package internally.
  - |
    cat >~/.pypirc <<EOL
    [distutils]
    index-servers = local
    [local]
    repository: ${ANALYTICS_PYPI_REPOSITORY}
    username: ${PYPI_USERNAME}
    password: ${PYPI_PASSWORD}
    EOL
  - python setup.py sdist upload --repository "${ANALYTICS_PYPI_REPOSITORY}"

test:internal:
  extends: 
    - .devex_internal_eks
    - .test
  variables:
    KFP_RUN_URL_PREFIX: "https://kubeflow.corp.dev-k8s.zg-aip.net/"
    KFP_SDK_NAMESPACE: "metaflow-integration-testing-internal"
  rules:
    - if: '$DEPLOY_INTERNAL == "true"'

test:nonprod:
  extends: 
    - .devex_nonprod_eks
    - .test
  variables:
    KFP_RUN_URL_PREFIX: "https://kubeflow.corp.stage-k8s.zg-aip.net/"
    KFP_SDK_NAMESPACE: "metaflow-integration-testing-stage"
  rules:
    - if: '$DEPLOY_NONPROD == "true"'

test:prod:
  extends: 
  - .devex_prod_eks
  - .test
  variables:
    KFP_RUN_URL_PREFIX: "https://kubeflow.corp.prod-k8s.zg-aip.net/"
    KFP_SDK_NAMESPACE: "metaflow-integration-testing-prod"
  rules:
    - if: '$DEPLOY_PROD == "true"'
